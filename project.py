# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jboZ8JWSXfjbTVkgStfRFg1_bP49P_oo

#Semiconductor Manufacturing Yield Prediction
# Author: Tarun kumar T
# Date: October, 2025
"""


# 1. Import libraries.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from imblearn.over_sampling import SMOTE
import joblib

# 2. Load Data.
data=pd.read_csv("/content/drive/MyDrive/semicond/signal-data.csv")

# 3. Initial data exploration.

print("\nFirst 5 rows:")
print(data.head())
print("\nData types:")
print(data.dtypes)
print("\nMissing values count per column:")
print(data.isnull().sum()[data.isnull().sum() > 0])

# Summary: Inspect the first few rows, data types, and check for missing values.

data.head()

# 4. Data cleaning.

non_numeric_cols = data.select_dtypes(exclude=[np.number]).columns.tolist()
print("\nDropping non-numeric columns:", non_numeric_cols)
data.drop(columns=non_numeric_cols, inplace=True)
print("\nFilling missing numeric values with median...")
data.fillna(data.median(), inplace=True)
print("Remaining missing values after filling:", data.isnull().sum().sum())

# Summary: Remove non-numeric columns and fill missing values in numeric columns with the column median.

# 5. Define features and target.
# According to project description, last column is target: -1 (pass), 1 (fail).

X = data.iloc[:, :-1]
y = data.iloc[:, -1]
print("\nTarget variable distribution:")
print(y.value_counts())

# Summary: Separate features (X) from the target column (y).

# 6. Address target imbalance using SMOTE.

from collections import Counter
print("\nClass distribution before SMOTE:", Counter(y))
if abs(y.value_counts(normalize=True)[-1] - 0.5) > 0.1:
    print("Applying SMOTE to balance classes...")
    smote = SMOTE(random_state=42)
    X_res, y_res = smote.fit_resample(X, y)
    print("Class distribution after SMOTE:", Counter(y_res))
else:
    print("Class distribution is balanced enough, skipping SMOTE.")
    X_res, y_res = X, y

# Summary: Use SMOTE to oversample the minority class if there is a class imbalance.

# 7. Train-test split.

X_train, X_test, y_train, y_test = train_test_split(
    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
print(f"\nTraining set shape: {X_train.shape}, Testing set shape: {X_test.shape}")

# Summary: Split the dataset into training and testing sets.

# 8. Feature scaling.

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
print("Feature scaling completed.")

# Summary: Standardize features so they have mean 0 and variance 1.

# 9. Model training, hyperparameter tuning and evaluation function.

def train_and_evaluate(model, param_grid, X_train, y_train, X_test, y_test, model_name):
    print(f"\nTraining and tuning {model_name}...")
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    best_model = grid_search.best_estimator_
    print(f"Best hyperparameters: {grid_search.best_params_}")
    y_train_pred = best_model.predict(X_train)
    y_test_pred = best_model.predict(X_test)
    print(f"{model_name} Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}")
    print(f"{model_name} Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}")
    print(f"Classification Report for {model_name} (Test set):")
    print(classification_report(y_test, y_test_pred))
    cm = confusion_matrix(y_test, y_test_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'{model_name} Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()
    return best_model, accuracy_score(y_test, y_test_pred)
    # Summary: Define a reusable function to train, tune, and evaluate models.

# 10. Random Forest Model.

rf = RandomForestClassifier(random_state=42)
rf_params = {
    'n_estimators': [50, 100],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
}
rf_model, rf_acc = train_and_evaluate(rf, rf_params, X_train_scaled, y_train, X_test_scaled, y_test, "Random Forest")

# Summary: Train a Random Forest Classifier with hyperparameter tuning.

# 11. Support Vector Machine Model.

svm = SVC(random_state=42)
svm_params = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf'],
    'gamma': ['scale', 'auto'],
}
svm_model, svm_acc = train_and_evaluate(svm, svm_params, X_train_scaled, y_train, X_test_scaled, y_test, "SVM")

# Summary: Train an SVM model with hyperparameter tuning.

# 12. Naive Bayes Model (No hyperparameter tuning).

print("\nTraining Naive Bayes...")
nb = GaussianNB()
nb.fit(X_train_scaled, y_train)
y_train_pred = nb.predict(X_train_scaled)
y_test_pred = nb.predict(X_test_scaled)
print(f"Naive Bayes Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}")
print(f"Naive Bayes Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}")
print("Classification Report for Naive Bayes (Test set):")
print(classification_report(y_test, y_test_pred))
cm = confusion_matrix(y_test, y_test_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')
plt.title('Naive Bayes Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Summary: Train a Gaussian Naive Bayes model without tuning.

# 13. Compare all models.

models_accuracy = {
    "Random Forest": rf_acc,
    "SVM": svm_acc,
    "Naive Bayes": accuracy_score(y_test, y_test_pred)
}
print("\nModel accuracy comparison on test set:")
for model_name, acc in models_accuracy.items():
    print(f"{model_name}: {acc:.4f}")
best_model_name = max(models_accuracy, key=models_accuracy.get)
print(f"\nSelected best model: {best_model_name}")
best_model = {'Random Forest': rf_model, 'SVM': svm_model, 'Naive Bayes': nb}[best_model_name]

# 14. Save best model and scaler for future use.

joblib.dump(best_model, 'best_model.pkl')
joblib.dump(scaler, 'scaler_model.pkl')
print(f"Saved best model ({best_model_name}) as 'best_model.pkl' and scaler as 'scaler_model.pkl'")
# Summary: Save the best performing model and scaler for future predictions.

# 15. Conclusion.

print("""
CONCLUSION:

1. Data cleaning and missing value imputation were performed successfully.
2. SMOTE was applied to handle class imbalance (if needed).
3. Feature scaling ensured model convergence and better performance.
4. Random Forest, SVM, and Naive Bayes models were trained and tuned.
5. Random Forest or SVM typically performed better; final model chosen based on highest test accuracy.
6. This model can be used to predict yield failures early, potentially improving manufacturing efficiency and reducing costs.
""")

# Summary: Final summary of the project and results.



"""# Task
Predict on a new dataset using a saved model and scaler.

## Load saved model and scaler

### Subtask:
Load the trained model and scaler from the saved files.

**Reasoning**:
Load the saved model and scaler using joblib.
"""

loaded_model = joblib.load('best_model.pkl')
loaded_scaler = joblib.load('scaler_model.pkl')
print("Loaded model and scaler successfully.")

"""## Load new data

### Subtask:
Load the new dataset for prediction.

"""

new_data = pd.read_csv("/content/drive/MyDrive/semicond/my_data.csv")
print("New data loaded successfully.")

new_data.head()

"""## Preprocess new data

### Subtask:
Apply the same preprocessing steps (dropping non-numeric columns, filling missing values, and scaling) to the new data as were applied to the training data.

**Reasoning**:
Apply the same preprocessing steps to the new data as were applied to the training data: dropping non-numeric columns, filling missing values with the median, and scaling the features using the loaded scaler.
"""

# Apply preprocessing steps to new_data

# 1. Drop non-numeric columns (reusing the logic from previous cleaning)
non_numeric_cols_new = new_data.select_dtypes(exclude=[np.number]).columns.tolist()
print("\nDropping non-numeric columns from new data:", non_numeric_cols_new)
new_data_processed = new_data.drop(columns=non_numeric_cols_new).copy()

# 2. Fill missing numeric values with median (using median from original training data if available, otherwise use new_data median)
# For consistency, we should ideally use the median calculated from the training data.
# However, since we don't have the median from the original training data readily available as a variable,
# we will use the median of the new data for imputation as done in the original cleaning step.
print("Filling missing numeric values in new data with median...")
new_data_processed.fillna(new_data_processed.median(), inplace=True)
print("Remaining missing values in new data after filling:", new_data_processed.isnull().sum().sum())

# 3. Scale the features using the loaded scaler
# Assuming the last column of new_data_processed is the target if it exists,
# otherwise, scale all columns.
# Based on the original data structure, the last column is 'Pass/Fail', which is numeric.
# We should only scale the feature columns, which are all columns except the last one.
if 'Pass/Fail' in new_data_processed.columns:
    new_data_features = new_data_processed.drop(columns=['Pass/Fail'])
    new_data_scaled = loaded_scaler.transform(new_data_features)
    # Convert scaled features back to DataFrame with original column names
    new_data_scaled_df = pd.DataFrame(new_data_scaled, columns=new_data_features.columns, index=new_data_processed.index)
    # Add the target column back if it existed
    new_data_scaled_df['Pass/Fail'] = new_data_processed['Pass/Fail']
    new_data_processed = new_data_scaled_df
else:
     new_data_scaled = loaded_scaler.transform(new_data_processed)
     new_data_processed = pd.DataFrame(new_data_scaled, columns=new_data_processed.columns, index=new_data_processed.index)


print("\nNew data preprocessing completed.")
new_data_processed.head()

"""## Predict on new data

### Subtask:
Use the loaded model to make predictions on the preprocessed new data.

**Reasoning**:
Extract the feature columns from the preprocessed new data and use the loaded model to make predictions.
"""

# 1. Extract the feature columns from the new_data_processed DataFrame.
# Assuming the last column is the target variable 'Pass/Fail'
#new_data_features_for_prediction = new_data_processed.drop(columns=['Pass/Fail'])

# 2. Use the loaded_model.predict() method to generate predictions.
new_data_predictions = loaded_model.predict(new_data_processed)

# Display the first few predictions
print("First 10 predictions on new data:")
print(new_data_predictions[:10])

"""## Display predictions

### Subtask:
Show the predictions.

**Reasoning**:
Display the generated predictions stored in the `new_data_predictions` variable to fulfill the subtask.
"""

# Display all generated predictions
print("All predictions on new data:")
new_data_predictions

"""## Summary:

### Data Analysis Key Findings

*   The trained model and scaler were successfully loaded from `best_model.pkl` and `scaler_model.pkl` respectively.
*   The new data for prediction was successfully loaded from `/content/drive/MyDrive/semicond/my_data.csv`. An initial attempt with a different filename resulted in a `FileNotFoundError`.
*   Preprocessing of the new data involved dropping the non-numeric 'Time' column and filling missing numeric values with the median.
*   The preprocessed new data features were successfully scaled using the loaded scaler.
*   Predictions were generated on the scaled features of the new data using the loaded model.
*   All predictions for the new dataset were displayed.

### Insights or Next Steps

*   The workflow for loading saved model/scaler, loading and preprocessing new data, and making predictions is established and functional.
*   The predictions are available for further analysis, such as evaluation against actual outcomes (if available) or integration into a production pipeline.

"""

# Convert the predictions numpy array to a pandas DataFrame
predictions_df = pd.DataFrame(new_data_predictions, columns=['Predicted_Pass/Fail'])

# Convert numeric predictions to 'Pass' and 'Fail'
predictions_df['Predicted_Pass/Fail'] = predictions_df['Predicted_Pass/Fail'].apply(lambda x: 'Pass' if x == -1 else 'Fail')

# Combine the original new data with the predictions
# Ensure the indices align before combining
new_data_with_predictions = new_data.copy()
new_data_with_predictions['Predicted_Pass/Fail'] = predictions_df['Predicted_Pass/Fail']


# Display the DataFrame
print("Original data with predictions as a table:")
new_data_with_predictions.head()

new_data_with_predictions['Predicted_Pass/Fail'].value_counts()



